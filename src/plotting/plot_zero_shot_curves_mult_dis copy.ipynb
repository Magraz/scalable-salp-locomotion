{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set font properties for entire plot\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'legend.fontsize': 18,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "})\n",
    "\n",
    "plotting_dir = Path().resolve()\n",
    "config_dir = plotting_dir / \"ppo_config.yaml\"\n",
    "\n",
    "with open(config_dir, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Determine number of mask files (disabled units configurations)\n",
    "num_masks = 9\n",
    "\n",
    "# Group data by batch first, then by experiment, then by n_agents, then by disabled_units\n",
    "batch_data = {batch: defaultdict(lambda: defaultdict(lambda: defaultdict(list))) for batch in config[\"batches\"]}\n",
    "reward_name = \"dist_rewards\"\n",
    "\n",
    "# First, collect all data points across trials\n",
    "for batch in config[\"batches\"]:\n",
    "    for experiment in config[\"experiments\"]:\n",
    "        for trial in config[\"trials\"]:\n",
    "            evaluation_file_name = f\"disabled_mask_eval\"\n",
    "            checkpoint_path = Path(f\"{config['base_path']}/{batch}/{experiment}/{trial}/logs/{evaluation_file_name}.dat\")\n",
    "\n",
    "            if checkpoint_path.is_file():\n",
    "                with open(checkpoint_path, \"rb\") as handle:\n",
    "                    data = pickle.load(handle)\n",
    "                    \n",
    "                    # data structure: {n_agents: {disabled_units: {'dist_rewards': [...], ...}}}\n",
    "                    for n_agents in data.keys():\n",
    "                        for disabled_units in data[n_agents].keys():\n",
    "                            # Append rewards from this trial to the list\n",
    "                            batch_data[batch][experiment][n_agents][disabled_units].extend(\n",
    "                                data[n_agents][disabled_units][reward_name]\n",
    "                            )\n",
    "                        \n",
    "                print(f\"Added trial {trial} data to {batch}/{experiment}\")\n",
    "\n",
    "# Extract training sizes from batch names (assuming format like \"batch_8\" or similar)\n",
    "batch_training_sizes = {}\n",
    "for batch in config[\"batches\"]:\n",
    "    # Try to extract number from batch name, or manually specify\n",
    "    # Adjust this based on your actual batch naming convention\n",
    "    if \"8\" in batch or batch == config[\"batches\"][0]:\n",
    "        batch_training_sizes[batch] = 8\n",
    "    elif \"16\" in batch or batch == config[\"batches\"][1]:\n",
    "        batch_training_sizes[batch] = 16\n",
    "    # Add more mappings as needed\n",
    "\n",
    "# Group by scale factor (evaluation_size / training_size)\n",
    "scale_factor_data = defaultdict(list)  # {scale_factor: [(batch, n_agents), ...]}\n",
    "\n",
    "for batch in config[\"batches\"]:\n",
    "    training_size = batch_training_sizes[batch]\n",
    "    for experiment in config[\"experiments\"]:\n",
    "        for n_agents in batch_data[batch][experiment].keys():\n",
    "            scale_factor = n_agents / training_size\n",
    "            scale_factor_data[scale_factor].append((batch, n_agents, experiment))\n",
    "\n",
    "# Sort scale factors\n",
    "sorted_scale_factors = sorted(scale_factor_data.keys())\n",
    "\n",
    "# Create a separate plot for each scale factor\n",
    "for scale_factor in sorted_scale_factors:\n",
    "    batch_agent_pairs = scale_factor_data[scale_factor]\n",
    "    \n",
    "    # Get unique batches for this scale factor\n",
    "    unique_batches = list(set([batch for batch, _, _ in batch_agent_pairs]))\n",
    "    \n",
    "    if not unique_batches:\n",
    "        continue\n",
    "    \n",
    "    # Create a figure with subplots: one column per batch\n",
    "    fig, axes = plt.subplots(1, len(unique_batches), figsize=(12 * len(unique_batches), 8), sharey=True)\n",
    "    if len(unique_batches) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Use a different color for each experiment\n",
    "    experiment_colors = {}\n",
    "    color_idx = 0\n",
    "    \n",
    "    # Store line objects and labels for shared legend\n",
    "    all_lines = []\n",
    "    all_labels = [\"gcn_mixed\", \"gat_mixed\", \"graph_transformer_mixed\", \"gcn_full\", \"gat_full\", \"graph_transformer_full\"]\n",
    "    \n",
    "    # Now plot each batch\n",
    "    for batch_idx, batch in enumerate(unique_batches):\n",
    "        ax = axes[batch_idx]\n",
    "        \n",
    "        # Get n_agents for this batch at this scale factor\n",
    "        n_agents = None\n",
    "        for b, n, _ in batch_agent_pairs:\n",
    "            if b == batch:\n",
    "                n_agents = n\n",
    "                break\n",
    "        \n",
    "        if n_agents is None:\n",
    "            continue\n",
    "        \n",
    "        training_size = batch_training_sizes[batch]\n",
    "        \n",
    "        # Set subplot title\n",
    "        ax.set_title(f\"Trained on {training_size} â†’ Evaluated on {n_agents} Salp-Units\")\n",
    "        \n",
    "        # Set y-label only for leftmost plot\n",
    "        if batch_idx == 0:\n",
    "            ax.set_ylabel(\"Normalized Mean Distance Reward\")\n",
    "        \n",
    "        # First pass: collect all means to find global min/max for normalization\n",
    "        all_means = []\n",
    "        experiment_data = {}\n",
    "        \n",
    "        for experiment in config[\"experiments\"]:\n",
    "            # Skip if no data for this experiment and n_agents\n",
    "            if n_agents not in batch_data[batch][experiment]:\n",
    "                print(f\"No data for {batch}/{experiment}/n_agents={n_agents}\")\n",
    "                continue\n",
    "            \n",
    "            # Get sorted list of disabled unit counts\n",
    "            disabled_units_list = sorted(batch_data[batch][experiment][n_agents].keys())\n",
    "            \n",
    "            if not disabled_units_list:\n",
    "                continue\n",
    "            \n",
    "            # Calculate mean and standard error for each disabled_units count\n",
    "            means = []\n",
    "            errors = []\n",
    "            for disabled_units in disabled_units_list:\n",
    "                rewards = batch_data[batch][experiment][n_agents][disabled_units]\n",
    "                if rewards:\n",
    "                    means.append(np.mean(rewards))\n",
    "                    errors.append(np.std(rewards) / np.sqrt(len(rewards)))\n",
    "                else:\n",
    "                    means.append(0)\n",
    "                    errors.append(0)\n",
    "            \n",
    "            experiment_data[experiment] = {\n",
    "                'disabled_units': disabled_units_list,\n",
    "                'means': means,\n",
    "                'errors': errors\n",
    "            }\n",
    "            all_means.extend(means)\n",
    "        \n",
    "        # Calculate global normalization parameters\n",
    "        if all_means and max(all_means) != min(all_means):\n",
    "            min_mean = min(all_means)\n",
    "            max_mean = max(all_means)\n",
    "            range_mean = max_mean - min_mean\n",
    "        else:\n",
    "            min_mean = 0\n",
    "            range_mean = 1\n",
    "        \n",
    "        # Second pass: normalize and plot\n",
    "        for experiment in config[\"experiments\"]:\n",
    "            if experiment not in experiment_data:\n",
    "                continue\n",
    "                \n",
    "            # Get consistent color for this experiment\n",
    "            if experiment not in experiment_colors:\n",
    "                experiment_colors[experiment] = plt.cm.tab10(color_idx+1 % 10)\n",
    "                color_idx += 1\n",
    "            color = experiment_colors[experiment]\n",
    "            \n",
    "            data = experiment_data[experiment]\n",
    "            disabled_units_list = data['disabled_units']\n",
    "            means = data['means']\n",
    "            errors = data['errors']\n",
    "            \n",
    "            # Normalize using global min/max\n",
    "            if range_mean > 0:\n",
    "                normalized_means = [(m - min_mean) / range_mean for m in means]\n",
    "                normalized_errors = [e / range_mean for e in errors]\n",
    "            else:\n",
    "                normalized_means = means\n",
    "                normalized_errors = errors\n",
    "            \n",
    "            # Print sample counts\n",
    "            sample_counts = [len(batch_data[batch][experiment][n_agents][d]) for d in disabled_units_list]\n",
    "            print(f\"{batch}/{experiment}/n_agents={n_agents}: {sample_counts} samples per disabled count\")\n",
    "            \n",
    "            # Plot with error bars\n",
    "            line = ax.errorbar(\n",
    "                disabled_units_list,\n",
    "                normalized_means,\n",
    "                yerr=normalized_errors,\n",
    "                fmt=\"o-\",\n",
    "                linewidth=2,\n",
    "                elinewidth=1,\n",
    "                markersize=6,\n",
    "                capsize=5,\n",
    "                color=color,\n",
    "                ecolor=color,\n",
    "                label=experiment\n",
    "            )\n",
    "            \n",
    "            # Store line and label for shared legend (only from first subplot)\n",
    "            if batch_idx == 0:\n",
    "                all_lines.append(line[0])\n",
    "        \n",
    "        ax.set_xlabel(\"Number of Disabled Salp Units\")\n",
    "        if disabled_units_list:\n",
    "            ax.set_xticks(disabled_units_list)\n",
    "        \n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Add horizontal line at 0.90\n",
    "        line_90 = ax.axhline(y=0.90, color='black', linestyle='--', linewidth=2)\n",
    "        \n",
    "        # Add legend only for the horizontal line in each subplot\n",
    "        ax.legend([line_90], ['90% performance'], loc='lower right', fontsize=16)\n",
    "\n",
    "        \n",
    "    \n",
    "    # Create a single legend for the entire figure (experiments only)\n",
    "    fig.legend(all_lines, all_labels, \n",
    "               loc='lower center',\n",
    "               bbox_to_anchor=(0.5, -0.08),\n",
    "               ncol=len(all_labels),\n",
    "               fontsize=18,\n",
    "               markerscale=2)\n",
    "    \n",
    "    # Add overall title with scale factor\n",
    "    scale_percentage = int(scale_factor * 100)\n",
    "    fig.suptitle(f\"Performance vs Disabled Units ({scale_percentage}% Scale)\", \n",
    "                 fontsize=22, y=0.98)\n",
    "    \n",
    "    # Adjust layout to make room for the legend and title\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.10, top=0.90)\n",
    "    \n",
    "    plt.savefig(f\"performance_vs_disabled_units_scale_{scale_percentage}pct.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scalable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
