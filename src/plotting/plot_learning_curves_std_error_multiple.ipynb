{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,\n",
    "    'axes.labelsize': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'legend.fontsize': 16,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "})\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "plotting_dir = Path().resolve()\n",
    "config_dir = plotting_dir / \"ppo_config.yaml\"\n",
    "\n",
    "with open(config_dir, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 7), sharey=True)  # sharey=True makes y-axis scale the same\n",
    "\n",
    "# Store data by batch and experiment\n",
    "batch_data = {}\n",
    "for batch in config[\"batches\"]:\n",
    "    batch_data[batch] = defaultdict(list)\n",
    "\n",
    "max_len = 0\n",
    "\n",
    "# First pass: collect data for each experiment grouped by batch\n",
    "for i, batch in enumerate(config[\"batches\"]):\n",
    "    datapoints = config[\"datapoints\"][i]\n",
    "    for experiment in config[\"experiments\"]:\n",
    "        for trial in config[\"trials\"]:\n",
    "            checkpoint_path = Path(f\"{config['base_path']}/{batch}/{experiment}/{trial}/logs/train.dat\")\n",
    "\n",
    "            if checkpoint_path.is_file():\n",
    "                with open(checkpoint_path, \"rb\") as handle:\n",
    "                    data = pickle.load(handle)[\"rewards_per_iteration\"][:datapoints]\n",
    "                    \n",
    "                    # Apply moving average\n",
    "                    if len(data) > config[\"moving_avg_window_size\"]:\n",
    "                        smoothed_data = moving_average(data, config[\"moving_avg_window_size\"])\n",
    "                        batch_data[batch][experiment].append(smoothed_data)\n",
    "                        max_len = max(max_len, len(smoothed_data))\n",
    "                    else:\n",
    "                        print(f\"Warning: {batch}/{experiment}/{trial} has too few data points for smoothing\")\n",
    "\n",
    "# Second pass: pad arrays to the same length if needed\n",
    "for batch in batch_data:\n",
    "    for exp in batch_data[batch]:\n",
    "        padded_data = []\n",
    "        for trial_data in batch_data[batch][exp]:\n",
    "            if len(trial_data) < max_len:\n",
    "                # Pad with NaN\n",
    "                padding = np.full(max_len - len(trial_data), np.nan)\n",
    "                padded_data.append(np.concatenate([trial_data, padding]))\n",
    "            else:\n",
    "                padded_data.append(trial_data)\n",
    "        \n",
    "        batch_data[batch][exp] = padded_data\n",
    "\n",
    "# Store line objects and labels for combined legend\n",
    "all_lines = []\n",
    "all_labels = [\"mlp\", \"gcn_mixed\", \"gat_mixed\", \"graph_transformer_mixed\", \"gcn_full\", \"gat_full\", \"graph_transformer_full\"]\n",
    "\n",
    "titles = [\"8 Salp-Unit Policy Learning Curve\", \"16 Salp-Unit Policy Learning Curve\"]\n",
    "\n",
    "# Plot each batch in its respective subplot\n",
    "for batch_idx, batch in enumerate(config[\"batches\"]):\n",
    "    ax = axes[batch_idx]\n",
    "    color_idx = 0\n",
    "\n",
    "    \n",
    "    # Add batch name as subplot title\n",
    "    ax.set_title(f\"{titles[batch_idx]}\")\n",
    "    \n",
    "    for exp in batch_data[batch]:\n",
    "        if not batch_data[batch][exp]:\n",
    "            print(f\"No data for {batch}/{exp}\")\n",
    "            continue\n",
    "            \n",
    "        # Convert list of arrays to 2D numpy array\n",
    "        data_array = np.array(batch_data[batch][exp])\n",
    "        \n",
    "        # Calculate mean and standard error across trials\n",
    "        mean_rewards = np.nanmean(data_array, axis=0)\n",
    "        \n",
    "        # Standard Error = StdDev / sqrt(n)\n",
    "        n_trials = np.sum(~np.isnan(data_array), axis=0)  # Count non-NaN values at each step\n",
    "        std_rewards = np.nanstd(data_array, axis=0)\n",
    "        se_rewards = std_rewards / np.sqrt(np.maximum(n_trials, 1))  # Avoid division by zero\n",
    "        \n",
    "        # X axis\n",
    "        x = np.arange(len(mean_rewards))\n",
    "        \n",
    "        # Get color for this experiment\n",
    "        color = plt.cm.tab10(color_idx % 10)\n",
    "        color_idx += 1\n",
    "        \n",
    "        # Plot mean line\n",
    "        line = ax.plot(x, mean_rewards, linewidth=2, label=exp, color=color)\n",
    "\n",
    "        # Store line and label for combined legend\n",
    "        # Only add to legend from first subplot to avoid duplicates\n",
    "        if batch_idx == 0:\n",
    "            all_lines.append(line[0])\n",
    "        \n",
    "        # Plot standard error band\n",
    "        ax.fill_between(\n",
    "            x,\n",
    "            mean_rewards - se_rewards,\n",
    "            mean_rewards + se_rewards,\n",
    "            alpha=0.3,\n",
    "            color=color\n",
    "        )\n",
    "        \n",
    "        print(f\"{batch}/{exp}: {len(batch_data[batch][exp])} trials\")\n",
    "\n",
    "    # Add legend, labels, grid to each subplot\n",
    "    # ax.legend(loc='upper left', fontsize=10)\n",
    "    ax.set_xlabel(\"Episodes\")\n",
    "    \n",
    "    # Only add y-label to the leftmost subplot\n",
    "    if batch_idx == 0:\n",
    "        ax.set_ylabel(\"Mean SCLD Reward\")\n",
    "        \n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Create a single legend for the entire figure\n",
    "fig.legend(all_lines, all_labels, \n",
    "           loc='lower center',  # Position below the subplots\n",
    "           bbox_to_anchor=(0.5, -0.12),  # Center horizontally, below plots\n",
    "           ncol=len(all_labels))\n",
    "\n",
    "# Add more padding at the bottom for the legend\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.05)  # Make room for the legend below plots\n",
    "\n",
    "plt.savefig(\"learning_curves_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
