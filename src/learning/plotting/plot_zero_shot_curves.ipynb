{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plotting_dir = Path().resolve()\n",
    "config_dir = plotting_dir / \"ppo_config.yaml\"\n",
    "\n",
    "with open(config_dir, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Group data by experiment first\n",
    "experiment_data = defaultdict(lambda: defaultdict(list))\n",
    "reward_name = \"dist_rewards\"\n",
    "\n",
    "# First, collect all data points across trials\n",
    "for batch in config[\"batches\"]:\n",
    "    for experiment in config[\"experiments\"]:\n",
    "        exp_key = f\"{batch}-{experiment}\"\n",
    "        \n",
    "        for trial in config[\"trials\"]:\n",
    "            checkpoint_path = Path(f\"{config['base_path']}/{batch}/{experiment}/{trial}/logs/evaluation.dat\")\n",
    "\n",
    "            if checkpoint_path.is_file():\n",
    "                with open(checkpoint_path, \"rb\") as handle:\n",
    "                    data = pickle.load(handle)\n",
    "                    \n",
    "                    # Group rewards by n_agents for this experiment\n",
    "                    for n in data.keys():\n",
    "                        experiment_data[exp_key][n].extend(data[n][reward_name])\n",
    "                        \n",
    "                print(f\"Added trial {trial} data to {exp_key}\")\n",
    "\n",
    "# Use a different color for each experiment\n",
    "experiment_colors = {}\n",
    "color_idx = 0\n",
    "\n",
    "# Now plot aggregated data with standard error\n",
    "for exp_key, agent_data in experiment_data.items():\n",
    "    # Get consistent color\n",
    "    if exp_key not in experiment_colors:\n",
    "        experiment_colors[exp_key] = plt.cm.tab10(color_idx % 10)\n",
    "        color_idx += 1\n",
    "    color = experiment_colors[exp_key]\n",
    "    \n",
    "    # Get sorted list of agent counts\n",
    "    n_agents = sorted(agent_data.keys())\n",
    "    \n",
    "    # Calculate mean and standard error across all trials\n",
    "    means = [np.mean(agent_data[n]) for n in n_agents]\n",
    "    errors = [np.std(agent_data[n]) / np.sqrt(len(agent_data[n])) for n in n_agents]\n",
    "    \n",
    "    # Print how many samples we have for each agent count\n",
    "    print(f\"{exp_key}: {[len(agent_data[n]) for n in n_agents]} samples per agent count\")\n",
    "    \n",
    "    # Plot with error bars\n",
    "    ax.errorbar(\n",
    "        n_agents,\n",
    "        means,\n",
    "        yerr=errors,\n",
    "        fmt=\"o-\",\n",
    "        linewidth=2,\n",
    "        elinewidth=1,\n",
    "        markersize=6,\n",
    "        capsize=5,\n",
    "        color=color,\n",
    "        ecolor=color,\n",
    "        label=exp_key.split(\"-\")[1]  # Just show experiment name without batch\n",
    "    )\n",
    "\n",
    "ax.set_xticks(n_agents)\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel(\"Number of Salp Units in Chain\")\n",
    "ax.set_ylabel(f\"Mean {reward_name.replace('_', ' ').title()}\")\n",
    "ax.set_title(\"Performance vs. Number of Salp Units (with SE across trials)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
